# Transformer-based-machine-translation
Transformer from scratch with BPE (byte pair encoding) tokenizer for machine translation

I took the transformer pytorch code from [here](https://github.com/bentrevett/pytorch-seq2seq) and I added the byte pair encoding tokenizer in it.
